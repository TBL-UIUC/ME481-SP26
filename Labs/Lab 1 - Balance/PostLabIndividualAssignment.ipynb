{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4122b2da",
   "metadata": {},
   "source": [
    "## ME 481: Whole Body Biomechanics - Balance Post-Lab Individual Assignment\n",
    "\n",
    "In this post-lab assignment, you will analyze the force plate data you collected during the balance lab. You'll apply the signal processing techniques learned in the pre-lab, calculate center of pressure (CoP) trajectories, and quantify postural control using standard balance metrics.\n",
    "\n",
    "**How to use this notebook:**\n",
    "- Each team member will analyze their own data individually in this notebook (Questions 1-4).\n",
    "- Each section has some code for you to complete. Each of these sections is denoted by \"#TODO\"\n",
    "- At the end of each section, complete the discussion questions\n",
    "- After completing this notebook individually, you will complete the group notebook together as a team.\n",
    "- Each team member should submit this completed notebook individually (**as HTML and .ipynb with your NetID appended to the filename**) to Canvas. One team member should submit the group assignment notebook (**as HTML and .ipynb**) to Canvas.\n",
    "\n",
    "**Assignment Structure:**\n",
    "- **Setup:** Imports and Mounting Google Drive\n",
    "- **Question 1:** Load Data and Convert Voltages to Forces and Moments\n",
    "- **Question 2:** Filter Force and Moment Signals\n",
    "- **Question 3:** Calculate and Plot Center of Pressure (CoP)\n",
    "- **Question 4:** Calculate CoP Balance Metrics\n",
    "- **Export Notebook** as HTML for Submission\n",
    "\n",
    "**Course Context:** This lab demonstrates a complete workflow for biomechanical data analysis: \n",
    "- Raw data acquisition\n",
    "- Signal processing\n",
    "- Analysis\n",
    "- Interpretation\n",
    "These skills are fundamental to experimental biomechanics research."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39907739",
   "metadata": {},
   "source": [
    "## Lab Overview and Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3579d1",
   "metadata": {},
   "source": [
    "### What Did We Measure in the Lab?\n",
    "\n",
    "In the lab, you performed tandem stance (heel-to-toe) balance tests under two conditions: **Eyes Open (EO)** and **Eyes Closed (EC)**. The AMTI force plate recorded six channels of raw voltage data representing forces (Fx, Fy, Fz) and moments (Mx, My, Mz) applied to its surface. By removing visual feedback in the EC condition, we isolated the contributions of vestibular and proprioceptive systems to postural control.\n",
    "\n",
    "### By the end of this assignment, you will be able to:\n",
    "\n",
    "1. **Transform raw sensor data** - Apply calibration matrices to convert voltage signals into biomechanically meaningful forces and moments\n",
    "2. **Apply signal processing** - Use spectral analysis and filtering to remove noise while preserving physiological signals\n",
    "3. **Calculate biomechanical metrics** - Compute center of pressure (CoP) trajectories from force plate data\n",
    "4. **Quantify postural control** - Calculate and interpret standard balance metrics used in clinical and research settings\n",
    "5. **Compare experimental conditions** - Evaluate how sensory disruption affects postural stability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c7c2a7",
   "metadata": {},
   "source": [
    "## Setup: Imports and Mounting Google Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7be1746",
   "metadata": {},
   "source": [
    "### A. Import Required Libraries\n",
    "\n",
    "Run the cell below to import all necessary libraries for data analysis, signal processing, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "578f334c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os  # For interacting with the operating system (e.g., file paths)\n",
    "import requests  # For making HTTP requests\n",
    "import nbformat  # For working with Jupyter Notebook file formats\n",
    "from nbconvert import HTMLExporter # For converting Jupyter Notebooks to HTML\n",
    "\n",
    "# Third-party library imports\n",
    "import numpy as np  # For numerical computations and array operations\n",
    "import pandas as pd  # For data manipulation and analysis using DataFrames\n",
    "from scipy.signal import welch, butter, filtfilt  # For signal processing (spectral density, filtering)\n",
    "import matplotlib.pyplot as plt  # For creating plots and visualizations\n",
    "\n",
    "# Jupyter-specific magic commands\n",
    "%matplotlib inline\n",
    "\n",
    "# Set default plot parameters\n",
    "plt.style.use('default')\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "plt.rcParams['xtick.labelsize'] = 'large'\n",
    "plt.rcParams['ytick.labelsize'] = 'large'\n",
    "plt.rcParams['font.family'] = 'Sans'\n",
    "plt.rcParams['mathtext.fontset'] = 'stix'\n",
    "plt.rcParams['figure.figsize'] = 10, 6\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['figure.autolayout'] = True\n",
    "plt.rcParams['axes.grid'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0ee404",
   "metadata": {},
   "source": [
    "### B. Connect to Google Drive and Set Working Directory\n",
    "\n",
    "Mount your Google Drive and set your working directory to your lab folder where your force plate data is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1948586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to your Google Drive (will ask you to log in and give access)\n",
    "from google.colab import drive, files\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2995df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your working directory to your lab folder\n",
    "# Replace with your group's folder path\n",
    "lab_folder = '/content/drive/MyDrive/ME481-BalanceLab'\n",
    "os.chdir(lab_folder)\n",
    "print(f\"✓ Working directory set to: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb74d71a",
   "metadata": {},
   "source": [
    "---\n",
    "## **Question 1: Convert Voltages to Forces and Moments**\n",
    "\n",
    "Convert the measured voltages into forces and moments and create a 6x1 subplot showing forces and moments for your eyes-open (EO) and eyes-closed (EC) data. Each subplot should have a single force/moment on the y-axis and time on the x-axis. Include a legend to differentiate the EO and EC conditions.\n",
    "\n",
    "### Instructions: Applying the Calibration Matrix\n",
    "\n",
    "To convert measured voltages into forces and moments, you need the inverted sensitivity matrix, $B$, the gain value from the amplifier, $G$, and the channel input voltage, $V_0$. For this specific force plate and amplifier:\n",
    "\n",
    "$$\n",
    "B = \\begin{bmatrix}\n",
    "2.9007     & 0.0200     & -0.0009     & -0.0253   & -0.0085      & 0.0090    \\\\\n",
    "-0.0067     & 2.9024   & -0.0520     & -0.0366   & -0.0149     & -0.0341   \\\\\n",
    "0.0046   & -0.0229     & 11.4206   & -0.0055     & 0.0055    & 0.0026      \\\\\n",
    "-0.0019     & 0.0035     & -0.0067     & 1.4559    & -0.0053     & -0.0028    \\\\\n",
    "0.0036     & 0.0011     & -0.0067     & 0.0018    & 1.1475     & -0.0008    \\\\\n",
    "0.0037     & 0.0145   & -0.0032   & 0.0006   & 0.0076     & 0.6188\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "```python\n",
    "# Python code to create the matrix\n",
    "B = np.array([\n",
    "    [2.9007,  0.0200, -0.0009, -0.0253, -0.0085,  0.0090],\n",
    "    [-0.0067, 2.9024, -0.0520, -0.0366, -0.0149, -0.0341],\n",
    "    [0.0046, -0.0229, 11.4206, -0.0055,  0.0055,  0.0026],\n",
    "    [-0.0019,  0.0035, -0.0067,  1.4559, -0.0053, -0.0028],\n",
    "    [0.0036,  0.0011, -0.0067,  0.0018,  1.1475, -0.0008],\n",
    "    [0.0037,  0.0145, -0.0032,  0.0006,  0.0076,  0.6188]\n",
    "])\n",
    "```\n",
    "\n",
    "$$\n",
    "G = 4000\n",
    "$$\n",
    "\n",
    "$$\n",
    "V_0 = 10 \\text{ volts}\n",
    "$$\n",
    "\n",
    "Assuming at a certain time-point $t_1$ we have a 1×6 voltage row vector $\\vec{V_1} = (V_{Fx}, V_{Fy}, \\ldots, V_{Mz})$, we can calculate the corresponding forces and moments, $\\vec{Y_1} =(F_{x}, F_{y}, \\ldots, M_{z})$ using:\n",
    "\n",
    "$$\n",
    "\\vec{Y_1} = \\frac{10^6}{GV_0}\\vec{V_1}\\boldsymbol{B^T}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8732d1dc",
   "metadata": {},
   "source": [
    "Start by loading your data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f523c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load your EO and EC data files\n",
    "# Set column names\n",
    "cols = ['Time', 'VFx', 'VFy', 'VFz', 'VMx', 'VMy', 'VMz']\n",
    "\n",
    "# Load EO and EC data\n",
    "# In the Colab file tree, you can right-click on your data files and select \"Copy path\" or \"Copy relative path\" to get the correct path\n",
    "eo_data = # TODO add code to load EO data using pd.read_csv() with the correct file path and column names\n",
    "ec_data = # TODO add code to load EC data using pd.read_csv() with the correct file path and column names\n",
    "\n",
    "# Inspect the first few rows of the data\n",
    "eo_data.head()\n",
    "ec_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30b4b18",
   "metadata": {},
   "source": [
    "Now convert voltages to forces/moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00b9ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "\n",
    "# 2. Define the calibration matrix B, gain G, and input voltage\n",
    "# Inverted sensitivity matrix, B\n",
    "B = np.array([\n",
    "    [2.9007,  0.0200, -0.0009, -0.0253, -0.0085,  0.0090],\n",
    "    [-0.0067, 2.9024, -0.0520, -0.0366, -0.0149, -0.0341],\n",
    "    [0.0046, -0.0229, 11.4206, -0.0055,  0.0055,  0.0026],\n",
    "    [-0.0019,  0.0035, -0.0067,  1.4559, -0.0053, -0.0028],\n",
    "    [0.0036,  0.0011, -0.0067,  0.0018,  1.1475, -0.0008],\n",
    "    [0.0037,  0.0145, -0.0032,  0.0006,  0.0076,  0.6188]\n",
    "])\n",
    "\n",
    "G = 4000  # Gain\n",
    "V_0 = 10  # Input voltage\n",
    "CF = 1e6/(G*V_0)  # Conversion Factor\n",
    "\n",
    "# 3. Convert voltages to forces/moments using the equation above\n",
    "V_EO = eo_data[['VFx', 'VFy', 'VFz', 'VMx', 'VMy', 'VMz']].to_numpy()\n",
    "V_EC = ec_data[['VFx', 'VFy', 'VFz', 'VMx', 'VMy', 'VMz']].to_numpy()\n",
    "\n",
    "F_EO = #TODO add code to compute F_EO using the conversion factor CF, calibration matrix B, and voltage data V_EO\n",
    "F_EC = #TODO add code to compute F_EC using the conversion factor CF, calibration matrix B, and voltage data V_EC\n",
    "\n",
    "# Assign back to DataFrames\n",
    "eo_data[['Fx', 'Fy', 'Fz', 'Mx', 'My', 'Mz']] = F_EO\n",
    "ec_data[['Fx', 'Fy', 'Fz', 'Mx', 'My', 'Mz']] = F_EC\n",
    "\n",
    "# Inspect the first few rows of the converted data\n",
    "eo_data.head()\n",
    "ec_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3371afa0",
   "metadata": {},
   "source": [
    "Now let's plot the calculated forces/moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5950055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Create a 6x1 subplot comparing EO and EC conditions\n",
    "fig, axes = plt.subplots(6, 1, figsize=(10, 8), dpi=100, sharex=True)\n",
    "cols = ['Fx', 'Fy', 'Fz', 'Mx', 'My', 'Mz']\n",
    "force_labels = ['$F_x$ [N]', '$F_y$ [N]', '$F_z$ [N]',\n",
    "                '$M_x$ [Nm]', '$M_y$ [Nm]', '$M_z$ [Nm]']\n",
    "\n",
    "for i, label in enumerate(cols):\n",
    "    axes[i].plot(#TODO, #TODO, label='EO', color='tab:blue')\n",
    "    axes[i].plot(#TODO, #TODO, label='EC', color='tab:orange')\n",
    "    axes[i].set_title(f'Comparison of {label} between EO and EC')\n",
    "    axes[i].set_ylabel(force_labels[i])\n",
    "    if i == 0:\n",
    "        axes[i].legend(loc='upper right')\n",
    "plt.xlabel('Time [s]')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af680bb",
   "metadata": {},
   "source": [
    "### Discussion Questions:\n",
    "\n",
    "1. How would an error in the gain $G$ or input voltage $V_0$ change the magnitude of your forces/moments?\n",
    "2. If a channel, such as $F_z$, looks incorrect or offset from expected values, what could a source of error be?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf28c74",
   "metadata": {},
   "source": [
    "# Your Answers Go Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd9d01a",
   "metadata": {},
   "source": [
    "---\n",
    "## **Question 2: Filter Force and Moment Signals**\n",
    "\n",
    "Evaluate the impact of cutoff frequency on one of your moment signals from Question 1. Then use a zero-phase-shift Butterworth filter on all calculated force/moment signals from Question 1.\n",
    "\n",
    "Use the provided functions to run spectral analysis on and filter all of your force and moment data for both EO and EC conditions. As a reminder, this function loops through each column of the input data frame that is not labeled as \"Time,\" calculates a unique cutoff frequency for that column, and then applies a zero-phase shift Butterworth filter to that column using the calculated cutoff frequency. Then, create two 6x1 subplots showing each filtered signal for both the EO and EC conditions.\n",
    "\n",
    "**This filtered force/moment data is what you will use for the remainder of the questions.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945d9faa",
   "metadata": {},
   "source": [
    "The following helper functions will be used throughout your analysis:\n",
    "- `spectral_analysis()` - Performs power spectral density analysis to determine optimal filter cutoff frequencies\n",
    "- `filter_timeseries_data()` - Applies a low-pass Butterworth filter to remove high-frequency noise\n",
    "\n",
    "Run the cell below to define these functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a26fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_analysis(\n",
    "    data, column_name, sampling_freq, nperseg=None, window=\"hann\", threshold=99, plot=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Perform spectral analysis on the given data using the Welch method. This function computes the power spectral density and cumulative power spectrum, optionally plotting the results. Cutoff frequency is selected based on a cumulative power threshold.\n",
    "\n",
    "    Args:\n",
    "        data (array-like): The input signal data for which spectral analysis is to be performed.\n",
    "        column_name (str): The name of the data used for plotting.\n",
    "        sampling_freq (float): The sampling frequency of the input data.\n",
    "        nperseg (int, optional): Length of each segment for the Welch method. If None, defaults to the length of the data.\n",
    "        window (str, optional): The window function to use. Defaults to 'hann'.\n",
    "        threshold (float): The percentage threshold for determining the cutoff frequency in the cumulative power spectrum.\n",
    "        plot (bool, optional): If True, generates plots for the power spectral density and cumulative power spectrum. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        float: The frequency at which the cumulative power spectrum exceeds the specified threshold.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the input data is empty or if the sampling frequency is non-positive.\n",
    "\n",
    "    Examples:\n",
    "        >>> freq = spectral_analysis(data, 1000, threshold=95, plot=True)\n",
    "    \"\"\"\n",
    "    data = np.asarray(data)\n",
    "\n",
    "    if len(data) == 0:\n",
    "        raise ValueError(\"Input data is empty\")\n",
    "\n",
    "    if sampling_freq <= 0:\n",
    "        raise ValueError(\"Sampling frequency must be positive\")\n",
    "\n",
    "    if nperseg is None:\n",
    "        nperseg = len(data)\n",
    "\n",
    "    f, Pxx = welch(data, fs=sampling_freq, nperseg=nperseg, window=window)\n",
    "\n",
    "    # Calculate cumulative power spectrum\n",
    "    cumulative_power = np.cumsum(Pxx)\n",
    "\n",
    "    # Normalize cumulative power to get a percentage\n",
    "    cumulative_power_percent = cumulative_power / cumulative_power[-1] * 100\n",
    "\n",
    "    # Find the index where the cumulative power levels off\n",
    "    cutoff_index = np.argmax(\n",
    "        cumulative_power_percent > threshold\n",
    "    )  # Use the specified threshold\n",
    "\n",
    "    if plot == True and column_name != \"Time\":\n",
    "        # Plot the results\n",
    "        plt.figure(figsize=(12, 6), dpi=100)\n",
    "        plt.suptitle(f'Spectral Analysis for: {column_name}')\n",
    "        # Plot Power Spectral Density\n",
    "        plt.subplot(2, 1, 1)\n",
    "        plt.semilogy(f, Pxx)\n",
    "        plt.title('Power Spectral Density')\n",
    "        plt.xlabel('Frequency (Hz)')\n",
    "        plt.ylabel('Power/Frequency (dB/Hz)')\n",
    "        plt.grid(True)\n",
    "\n",
    "        # Plot Cumulative Power Spectrum\n",
    "        plt.subplot(2, 1, 2)\n",
    "        plt.plot(f, cumulative_power_percent)\n",
    "        plt.axvline(x=f[cutoff_index], color='r', linestyle='--',\n",
    "                    label=f'Cutoff Frequency: {f[cutoff_index]:.2f} Hz')\n",
    "        plt.title('Cumulative Power Spectrum')\n",
    "        plt.xlabel('Frequency (Hz)')\n",
    "        plt.ylabel('Cumulative Power (%)')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    return f[cutoff_index]\n",
    "\n",
    "\n",
    "def filter_timeseries_data(data, sampling_freq, custom_cutoff_frequency=None, threshold=99, plot=False):\n",
    "    \"\"\"\n",
    "    Filter time series data using a low-pass Butterworth filter. This function applies a moving average smoothing filter before the Butterworth filter to each column of the input data besides the column named 'Time', based on a specified or calculated cutoff frequency.\n",
    "\n",
    "    Args:\n",
    "        data (DataFrame): The input time series data to be filtered. Must be a pandas DataFrame.\n",
    "        sampling_freq (float): The sampling frequency of the input data.\n",
    "        custom_cutoff_frequency (float, optional): A user-defined cutoff frequency for the filter. If not provided, it will be determined using spectral analysis.\n",
    "        threshold (float): Cumulative power threshold for automatic cutoff determination. Defaults to 99.\n",
    "        plot (bool): Whether to plot spectral analysis results. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: The filtered time series data, with the same structure as the input.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the input data is not a pandas DataFrame.\n",
    "\n",
    "    Examples:\n",
    "        >>> filtered_data = filter_timeseries_data(data, sampling_freq=1000, threshold=95, plot=False)\n",
    "    \"\"\"\n",
    "    if not isinstance(data, (pd.DataFrame)):\n",
    "        raise ValueError(\n",
    "            \"Unsupported data type. Please provide a pandas DataFrame.\")\n",
    "\n",
    "    fs = float(sampling_freq)\n",
    "\n",
    "    def apply_filter(column, cutoff_frequency):\n",
    "        column = np.asarray(column)\n",
    "        b, a = butter(N=4, Wn=cutoff_frequency,\n",
    "                      btype=\"low\", fs=fs, output=\"ba\")\n",
    "        return filtfilt(b, a, column)\n",
    "\n",
    "    if custom_cutoff_frequency is None:\n",
    "        cutoff_frequencies = {column: float(spectral_analysis(\n",
    "            data[column], column, sampling_freq, threshold=threshold, plot=plot)) for column in data.columns}\n",
    "    else:\n",
    "        cutoff_frequencies = {\n",
    "            column: custom_cutoff_frequency for column in data.columns}\n",
    "\n",
    "    filtered_data = data.apply(lambda column: apply_filter(\n",
    "        column, cutoff_frequencies[column.name]) if column.name != \"Time\" else column)\n",
    "\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a198f3e9",
   "metadata": {},
   "source": [
    "Now let's perform spectral analysis to calculate cutoff frequencies for each component. Decide on a cumulative power threshold for filtering and assign it in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e030514c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Run spectral analysis on each force/moment component to determine cutoff frequencies\n",
    "f_cutoffs_eo = {}\n",
    "f_cutoffs_ec = {}\n",
    "for column in ['Fx', 'Fy', 'Fz', 'Mx', 'My', 'Mz']:\n",
    "    if column != 'Time':\n",
    "        print(f\"Analyzing {column} for EO condition...\")\n",
    "        f_cutoffs_eo[column] = spectral_analysis(\n",
    "            eo_data[column], column, sampling_freq=1000, threshold=#TODO, plot=True)\n",
    "        print(f\"Analyzing {column} for EC condition...\")\n",
    "        f_cutoffs_ec[column] = spectral_analysis(\n",
    "            ec_data[column], column, sampling_freq=1000, threshold=#TODO, plot=True)\n",
    "\n",
    "# 2. Print the cutoff frequencies for EO and EC conditions\n",
    "print(\"Cutoff Frequencies for EO Condition:\")\n",
    "for key, value in f_cutoffs_eo.items():\n",
    "    print(f\"{key}: {value:.2f} Hz\")\n",
    "print(\"\\nCutoff Frequencies for EC Condition:\")\n",
    "for key, value in f_cutoffs_ec.items():\n",
    "    print(f\"{key}: {value:.2f} Hz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c1a5c1",
   "metadata": {},
   "source": [
    "Now let's use our provided filtering function to perform low-pass filtering on our data based on spectral analysis. Use the same cumulative power threshold as you picked above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45faf944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Filter the EO and EC data using the determined cutoff frequencies\n",
    "filtered_eo = filter_timeseries_data(\n",
    "    eo_data[['Fx', 'Fy', 'Fz', 'Mx', 'My', 'Mz']],\n",
    "    sampling_freq=1000,\n",
    "    threshold=#TODO,\n",
    "    plot=False\n",
    ")\n",
    "filtered_ec = filter_timeseries_data(\n",
    "    ec_data[['Time', 'Fx', 'Fy', 'Fz', 'Mx', 'My', 'Mz']],\n",
    "    sampling_freq=1000,\n",
    "    threshold=#TODO,\n",
    "    plot=False,\n",
    ")\n",
    "\n",
    "for col in ['Fx', 'Fy', 'Fz', 'Mx', 'My', 'Mz']:\n",
    "    eo_data[f'{col}_filtered'] = filtered_eo[col]\n",
    "    ec_data[f'{col}_filtered'] = filtered_ec[col]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788c3fb4",
   "metadata": {},
   "source": [
    "Plot the filtered vs unfiltered data to see differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f4345f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Create two 6x1 subplots comparing filtered vs unfiltered data for EO and EC conditions\n",
    "fig, axes = plt.subplots(6, 1, figsize=(10, 8), dpi=100, sharex=True)\n",
    "force_labels = ['Fx', 'Fy', 'Fz', 'Mx', 'My', 'Mz']\n",
    "for i, label in enumerate(force_labels):\n",
    "    axes[i].plot(eo_data['Time'], eo_data[label],\n",
    "                 label='Unfiltered EO', color='tab:gray', alpha=0.5)\n",
    "    axes[i].plot(eo_data['Time'], eo_data[label + '_filtered'],\n",
    "                 label='Filtered EO', color='tab:blue')\n",
    "    axes[i].set_title(f'EO Condition: {label} - Filtered vs Unfiltered')\n",
    "    axes[i].set_ylabel(label)\n",
    "    axes[i].legend()\n",
    "plt.xlabel('Time')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig, axes = plt.subplots(6, 1, figsize=(10, 8), dpi=100, sharex=True)\n",
    "for i, label in enumerate(force_labels):\n",
    "    axes[i].plot(ec_data['Time'], ec_data[label],\n",
    "                 label='Unfiltered EC', color='tab:gray', alpha=0.5)\n",
    "    axes[i].plot(ec_data['Time'], ec_data[label + '_filtered'],\n",
    "                 label='Filtered EC', color='tab:orange')\n",
    "    axes[i].set_title(f'EC Condition: {label} - Filtered vs Unfiltered')\n",
    "    axes[i].set_ylabel(label)\n",
    "    axes[i].legend()\n",
    "plt.xlabel('Time')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee6a4dd",
   "metadata": {},
   "source": [
    "### Discussion Questions\n",
    "1. What cumulative power threshold did you pick for spectral analysis? Justify your choice.\n",
    "2. How could your chosen cutoff frequency affect the balance metrics later in the notebook?\n",
    "3. If EO and EC conditions yield different cutoff frequencies, what does that imply about the differences in sway patterns between the conditions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7134e14",
   "metadata": {},
   "source": [
    "# Your Answers Go Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c81937",
   "metadata": {},
   "source": [
    "---\n",
    "## **Question 3: Calculate and Plot Center of Pressure (CoP)**\n",
    "\n",
    "Calculate the center of pressure (CoP) location and create a 1x2 subplot to show the CoP location (x,y) for all time points (stabilogram) for the EO and EC conditions. Use your filtered force/moment data from Question 2.\n",
    "\n",
    "### Instructions: Calculating CoP Location\n",
    "\n",
    "To find the location of the Center of Pressure (CoP), you need information about the force plate's shear center relative to its geometric center. The difference between the shear center and geometric center are negligible in the $x$ and $y$ directions, so we only consider the $z$ direction. For this specific force plate:\n",
    "\n",
    "$$\n",
    "z_0 = -37.645 \\text{ mm}\n",
    "$$\n",
    "\n",
    "Assuming at a certain time-point $t_i$ we have the 1×6 row vector with forces and moments $\\vec{Y_i}=(F_{x,i},F_{y,i},F_{z,i},M_{x,i},M_{y,i},M_{z,i})$, we can calculate the CoP location using:\n",
    "\n",
    "$$\n",
    "CoP_{x,i}=\\frac{M_{y,i}-z_0F_{x,i}}{F_{z,i}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "CoP_{y,i}=\\frac{M_{x,i}+z_0F_{y,i}}{F_{z,i}}\n",
    "$$\n",
    "\n",
    "**Important:** Be careful with the moment units and the units of $z_0$. They must be consistent for your CoP calculations.\n",
    "\n",
    "### Creating the Stabilogram Plot\n",
    "\n",
    "Before making your 1×2 stabilogram subplot:\n",
    "- **Center the CoP data** by subtracting the mean $\\overline{CoP_x}$ and $\\overline{CoP_y}$ from each time point so the stabilogram is centered at the origin.\n",
    "- Select the same axis limits to more easily compare the two conditions\n",
    "- Clearly label your axes using appropriate anatomical conventions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a8e2b9",
   "metadata": {},
   "source": [
    "Let's first start by calculating $\\text{CoP}_x$ and $\\text{CoP}_y$ for each condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede2a966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Calculate CoP x and y positions using the equations above\n",
    "z_0 = -37.645*1e-3  # (m) Shear center relative to geometric center\n",
    "COP_EO = pd.DataFrame(columns=['COPx', 'COPy']) # Create empty DataFrame to store CoP results for EO condition\n",
    "COP_EC = pd.DataFrame(columns=['COPx', 'COPy']) # Create empty DataFrame to store CoP results for EC condition\n",
    "\n",
    "#TODO - Calculate COP_EO and COP_EC using the equations provided, utilizing the filtered force and moment data from eo_data and ec_data respectively. Use the empty dataframes created above to store the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868ed0e1",
   "metadata": {},
   "source": [
    "Center the CoP data about the origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5981f08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Center the CoP data about the origin\n",
    "#TODO - Center the CoP data by subtracting the mean from each column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ee6f92",
   "metadata": {},
   "source": [
    "Create stabilogram plots for comparing the two conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fe5ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Create stabilogram plots comparing EO and EC conditions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6), dpi=100) # Create a 1x2 subplot for EO and EC conditions\n",
    "\n",
    "# Determine maximum range for centering plots about origin\n",
    "x_max = #TODO add code to calculate x_max using the maximum absolute values of the centered CoP x positions from both EO and EC conditions, multiplied by 1.1 for padding\n",
    "y_max = #TODO add code to calculate y_max using the maximum absolute values of the centered CoP y positions from both EO and EC conditions, multiplied by 1.1 for padding\n",
    "\n",
    "max_range = max(x_max, y_max)  # Ensure equal scaling in both axes\n",
    "\n",
    "# First subplot for EO condition\n",
    "axes[0].plot(#TODO,#TODO, color='tab:blue') # add code to finish this line to plot the centered CoP x and y positions for EO condition\n",
    "# TODO set the plot title\n",
    "# TODO set the x and y labels. Hint: make sure to include the units in the labels\n",
    "# TODO set the x and y limits to be centered about the origin using max_range\n",
    "axes[0].set_aspect('equal', adjustable='box') # This ensures that the x and y axes have the same scale, which is important for accurately interpreting the sway patterns in the stabilogram.\n",
    "axes[0].grid(True) # Add grid lines\n",
    "\n",
    "# Second subplot for EC condition\n",
    "# TODO create the second subplot for EC condition by plotting the centered CoP x and y positions for EC condition, setting the title, labels, limits, aspect ratio, and grid lines similar to the EO subplot above. Use axes[1] for the EC subplot.\n",
    "axes[1].plot(#TODO,#TODO, color='tab:orange') # add code to finish this line to plot the centered CoP x and y positions for EO condition\n",
    "\n",
    "plt.tight_layout() # Adjust layout to prevent overlap\n",
    "plt.show() # Display the stabilogram plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cb5f5a",
   "metadata": {},
   "source": [
    "### Discussion Questions:\n",
    "\n",
    "1. Why might CoP be more sensitive than CoM for detecting balance changes?\n",
    "2. Why is centering the CoP data important before comparing EO and EC stabilograms?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2beb3b06",
   "metadata": {},
   "source": [
    "# Your Answers Go Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d270ee2",
   "metadata": {},
   "source": [
    "---\n",
    "## **Question 4: Calculate Balance Metrics**\n",
    "\n",
    "Calculate and report the following balance metrics for the EO and EC conditions using the centered data:\n",
    "\n",
    "- **Anterior-posterior (AP) excursion range**\n",
    "\n",
    "    $$ \\text{CoP}_{AP,max} - \\text{CoP}_{AP,min} $$\n",
    "\n",
    "- **Medial-lateral (ML) excursion range**\n",
    "\n",
    "    $$ \\text{CoP}_{ML,max} - \\text{CoP}_{ML,min} $$\n",
    "\n",
    "- **Path length**\n",
    "\n",
    "    $$\n",
    "    \\text{Path Length}=\\sum_{i=2}^{N}\\sqrt{(\\text{CoP}_{x,i}-\\text{CoP}_{x,i-1})^2+(\\text{CoP}_{y,i}-\\text{CoP}_{y,i-1})^2}\n",
    "    $$\n",
    "\n",
    "- **Average CoP speed**\n",
    "\n",
    "    $$\n",
    "    \\frac{\\text{path length}}{T}\n",
    "    $$\n",
    "\n",
    "    where $T$ is the total time\n",
    "\n",
    "- **Mean excursion distance**\n",
    "\n",
    "    $$\n",
    "    \\begin{aligned} \n",
    "    d_i&=\\sqrt{\\text{CoP}_{x,i}^2+\\text{CoP}_{y,i}^2} \\\\\n",
    "    \\bar{d}&=\\frac{1}{N}\\sum_{i=1}^{N}d_i\n",
    "    \\end{aligned}\n",
    "    $$\n",
    "\n",
    "- **Standard deviation of excursion distance**\n",
    "\n",
    "    $$\n",
    "    \\begin{aligned}\n",
    "    \\sigma_d&=\\sqrt{\\frac{1}{N-1}\\sum_{i=1}^{N}(d_i-\\bar{d})^2}\n",
    "    \\end{aligned}\n",
    "    $$\n",
    "\n",
    "- **Angular deviation from AP axis**\n",
    "\n",
    "    $$\n",
    "    \\theta_i=\\arctan\\left(\\frac{\\Delta \\text{CoP}_{y,i}}{\\Delta \\text{CoP}_{x,i}}\\right), \\quad\n",
    "    \\text{Angular Deviation}=\\frac{1}{N-1}\\sum_{i=1}^{N-1}\\left|\\theta_i\\right|\\cdot\\frac{180}{\\pi}\n",
    "    $$\n",
    "\n",
    "    Note: make sure to use the math.atan2() or np.atan2() function to automatically adjust for quadrant\n",
    "\n",
    "- **Area of 95% confidence ellipse**\n",
    "\n",
    "    $$\n",
    "    A_{ellipse,95\\%} = \\pi \\cdot a \\cdot b = \\pi \\cdot 2\\sqrt{5.991 \\lambda_1} \\cdot 2\\sqrt{5.991 \\lambda_2}\n",
    "    $$\n",
    "\n",
    "    where $\\lambda_1$ and $\\lambda_2$ are the eigenvalues of the covariance matrix of the centered CoP data, and $a$, $b$ are the semi-major and semi-minor axes, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909434aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Calculate the following CoP metrics for both EO and EC conditions\n",
    "\n",
    "# Initialize dictionaries to store CoP metrics for EO and EC conditions\n",
    "EO_metrics = {\n",
    "    \"AP_Excursion_Range\": None,\n",
    "    \"ML_Excursion_Range\": None,\n",
    "    \"Path_Length\": None,\n",
    "    \"Average_CoP_Speed\": None,\n",
    "    \"Mean_Excursion_Distance\": None,\n",
    "    \"Std_Excursion_Distance\": None,\n",
    "    \"Angular_Deviation\": None,\n",
    "    \"Ellipse_Area_95\": None,\n",
    "}\n",
    "EC_metrics = {\n",
    "    \"AP_Excursion_Range\": None,\n",
    "    \"ML_Excursion_Range\": None,\n",
    "    \"Path_Length\": None,\n",
    "    \"Average_CoP_Speed\": None,\n",
    "    \"Mean_Excursion_Distance\": None,\n",
    "    \"Std_Excursion_Distance\": None,\n",
    "    \"Angular_Deviation\": None,\n",
    "    \"Ellipse_Area_95\": None,\n",
    "}\n",
    "\n",
    "# Anterior-Posterior Excursion Range\n",
    "# TODO add code to calculate based on the equations above and assign to EO_metrics and EC_metrics dictionaries\n",
    "\n",
    "# Medial-Lateral Excursion Range\n",
    "# TODO add code to calculate based on the equations above and assign to EO_metrics and EC_metrics dictionaries\n",
    "\n",
    "# Path Length\n",
    "# TODO add code to calculate based on the equations above and assign to EO_metrics and EC_metrics dictionaries\n",
    "\n",
    "# Average CoP Speed\n",
    "# TODO add code to calculate based on the equations above and assign to EO_metrics and EC_metrics dictionaries\n",
    "\n",
    "# Mean Excursion Distance\n",
    "# TODO add code to calculate based on the equations above and assign to EO_metrics and EC_metrics dictionaries\n",
    "\n",
    "# Standard Deviation of Excursion Distance\n",
    "# TODO add code to calculate based on the equations above and assign to EO_metrics and EC_metrics dictionaries\n",
    "\n",
    "# Angular Deviation from Anterior-Posterior Axis\n",
    "def angular_deviation(cop_data):\n",
    "    \"\"\"\n",
    "    Calculate the mean angular deviation of CoP trajectory from the anterior-posterior (AP) axis.\n",
    "\n",
    "    Args:\n",
    "        cop_data (DataFrame): DataFrame containing 'COPx_centered' and 'COPy_centered' columns.\n",
    "\n",
    "    Returns:\n",
    "        float: Mean absolute angular deviation in degrees from the AP axis (y-axis).\n",
    "    \"\"\"\n",
    "    delta_x = np.diff(cop_data['COPx_centered'])\n",
    "    delta_y = np.diff(cop_data['COPy_centered'])\n",
    "    #TODO add code to calculate the angles of the CoP trajectory segments relative to the AP axis using arctan2, then take the absolute value and convert to degrees. Finally, return the mean.\n",
    "    return \n",
    "\n",
    "\n",
    "EO_metrics['Angular_Deviation'] = angular_deviation(COP_EO)\n",
    "EC_metrics['Angular_Deviation'] = angular_deviation(COP_EC)\n",
    "\n",
    "# Area of 95% Confidence Ellipse. This code has been provided for you. There is nothing to complete here.\n",
    "def ellipse_area(cop_data):\n",
    "    \"\"\"\n",
    "    Calculate the area of a 95% confidence ellipse from CoP data.\n",
    "\n",
    "    Args:\n",
    "        cop_data (DataFrame): DataFrame containing COPx_centered and COPy_centered columns\n",
    "\n",
    "    Returns:\n",
    "        float: Area of the 95% confidence ellipse\n",
    "    \"\"\"\n",
    "    cov_matrix = np.cov(cop_data['COPx_centered'],\n",
    "                        cop_data['COPy_centered'])  # Covariance matrix\n",
    "    eigenvalues, _ = np.linalg.eig(cov_matrix)  # Eigenvalues and eigenvectors\n",
    "    a = 2 * np.sqrt(5.991 * eigenvalues[0])  # Semi-major axis 95% confidence\n",
    "    b = 2 * np.sqrt(5.991 * eigenvalues[1])  # Semi-minor axis 95% confidence\n",
    "    return np.pi * a * b\n",
    "\n",
    "\n",
    "# Calculate ellipse areas\n",
    "EO_metrics['Ellipse_Area_95'] = ellipse_area(COP_EO)\n",
    "EC_metrics['Ellipse_Area_95'] = ellipse_area(COP_EC)\n",
    "\n",
    "# Print the calculated CoP metrics for both EO and EC conditions\n",
    "print(\"CoP Metrics for EO Condition:\")\n",
    "for key, value in EO_metrics.items():\n",
    "    print(f\"{key}: {value:.2f}\")\n",
    "print(\"\\nCoP Metrics for EC Condition:\")\n",
    "for key, value in EC_metrics.items():\n",
    "    print(f\"{key}: {value:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa73d9a8",
   "metadata": {},
   "source": [
    "Now let's calculate the percent change of each metric between the two conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b03eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print the percentage changes between EO and EC conditions for each metric\n",
    "print(\"\\nPercentage Changes from EO to EC Condition:\")\n",
    "for key in EO_metrics.keys():\n",
    "    percent_change = #TODO add code to calculate the percentage change from EO to EC for each metric using the formula: ((EC - EO) / EO) * 100\n",
    "    print(f\"{key}: {percent_change:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f11fee1",
   "metadata": {},
   "source": [
    "### Discussion Questions:\n",
    "\n",
    "1. Which metrics changed the most between the two conditions? Which changed the least? Explain what differences in these metrics imply about the CoP trajectory.\n",
    "2. There are many CoP metrics that have been reported in balance literature. Find a metric that we didn't use and define it. Please also provide the source in APA format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb9bca1",
   "metadata": {},
   "source": [
    "# Your Answers Go Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a56c81a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Export Notebook as HTML for Submission\n",
    "\n",
    "Run the cells below to export this notebook as an HTML file for submission to Canvas.\n",
    "\n",
    "**Submission Requirements:**\n",
    "- Upload both the `.ipynb` file and the exported `.html` file to Canvas\n",
    "- Open the HTML file before submitting to confirm everything is readable and appears as expected\n",
    "- Ensure all code cells have been run and all outputs are visible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e91b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to export notebook as HTML\n",
    "def export_current_notebook(notebook_path, output_filename=\"exported_notebook.html\"):\n",
    "    \"\"\"\n",
    "    Exports the specified Colab notebook (with all cell outputs) as an HTML file.\n",
    "\n",
    "    Parameters:\n",
    "    - notebook_path (str): The full path to the notebook file to export.\n",
    "    - output_filename (str): The name of the output HTML file (default is \"exported_notebook.html\").\n",
    "\n",
    "    This function reads the notebook file, converts it to an HTML file,\n",
    "    and saves the output with the given filename. It also initiates a download of the HTML file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the notebook file\n",
    "        with open(notebook_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            notebook_content = nbformat.read(f, as_version=4)\n",
    "\n",
    "        # Convert notebook to HTML\n",
    "        html_exporter = HTMLExporter()\n",
    "\n",
    "        # Ensure that input and output cells are included in the exported HTML\n",
    "        html_exporter.exclude_input = False  # Include code input\n",
    "        html_exporter.exclude_output = False  # Ensure that outputs are captured\n",
    "\n",
    "        # Export the notebook to HTML\n",
    "        html_data, _ = html_exporter.from_notebook_node(notebook_content)\n",
    "\n",
    "        # Add CSS to wrap lines and prevent clipping\n",
    "        wrap_css = \"\"\"\n",
    "        <style>\n",
    "            pre, code {\n",
    "                word-wrap: break-word;\n",
    "                white-space: pre-wrap;\n",
    "                word-break: break-word;\n",
    "            }\n",
    "        </style>\n",
    "        \"\"\"\n",
    "\n",
    "        # Insert the CSS at the top of the HTML document\n",
    "        html_data = wrap_css + html_data\n",
    "\n",
    "        # Save the HTML file\n",
    "        with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(html_data)\n",
    "\n",
    "        print(f\"Notebook exported successfully as {output_filename}\")\n",
    "\n",
    "        # Download the file\n",
    "        files.download(output_filename)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "# Update these paths to match your notebook location and desired output name\n",
    "# Change to your notebook path\n",
    "# TODO: Update this path to point to your notebook in your Google Drive. You can right-click on the notebook file in the Colab file tree and select \"Copy path\" or \"Copy relative path\" to get the correct path. Make sure your NetID is included in the filename.\n",
    "notebook_to_export = '/content/drive/MyDrive/ME481-BalanceLab/BalancePostLabIndividualAssignment-NetID.ipynb'\n",
    "\n",
    "# This will save to your downloads folder\n",
    "output_filename = 'BalancePostLabIndividualAssignment-NetID.html'\n",
    "\n",
    "# Export the notebook\n",
    "export_current_notebook(notebook_path=notebook_to_export,\n",
    "                        output_filename=output_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "me481",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

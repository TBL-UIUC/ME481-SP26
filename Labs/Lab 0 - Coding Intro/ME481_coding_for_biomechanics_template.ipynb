{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c346145",
   "metadata": {},
   "source": [
    "## Coding for biomechanics\n",
    "\n",
    "By completing this notebook, you will...\n",
    "1. Learn about a few important python data structures\n",
    "2. Learn about python functions and how to use them\n",
    "3. Load, inspect, and visualize real biomechanics data\n",
    "4. Learn about the basics of debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4270355b",
   "metadata": {},
   "source": [
    "## Package imports\n",
    "\n",
    "You can find a python package for just about anything, but you will need to install it using pip/conda before importing it. One big upside of Google Colab is that is has many popular data science, machine learning, and visuzliation libraries pre-installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1008cbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Often we import libraries at the start of our code and we may use a shorthand for them (i.e. import packagename as pckg)\n",
    "\n",
    "import numpy as np # A versatile packages for scientific computing\n",
    "import matplotlib.pyplot as plt  # A package for plotting and visualization\n",
    "import pandas as pd # A package for data loading and manipulation\n",
    "import requests  # A package for downloading files from the internet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3890f42",
   "metadata": {},
   "source": [
    "## 1. Python data structures (containers)\n",
    "\n",
    "There are many data types in python. You should be aware of a few common data types and know how to check the data type of an object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958d9fb2",
   "metadata": {},
   "source": [
    "**1.1 Lists**\n",
    "\n",
    "Let's define a list, which is just an ordered container. Notice that you can add or delete items, or reorder the list. This container can be *indexed*, meaning we can grab the $i^{th}$ element by placing $[i]$ after a list object. **Note:** Python indexing begins at zero. MATLAB indexing begins at one. **This trips many people up!**\n",
    "\n",
    "The NumPy package contains a data type known as an ndarray. They are very similar to lists, but they do not allow you to mix data types within the same container. They are more computationally efficient than traditional python lists and are used extensively in scientific libraries like Pandas, Scipy, and Scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fd7c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Marker positions over time (X coordinate only)\n",
    "x_positions = [0.1, 0.15, 0.23, 0.31, 0.40]\n",
    "print(f\"First value: {x_positions[0]}\")\n",
    "print(f\"Length: {len(x_positions)}\")\n",
    "\n",
    "# Check the type of x_positions\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Let's create an array of time values between 0 and 0.4 seconds, with the same length as x_positions using the numpy package\n",
    "times = # YOUR CODE HERE\n",
    "\n",
    "# Now let's \"cast\" our array to a list\n",
    "time_list = # YOUR CODE HERE\n",
    "print(f\"Our list: {time_list}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7d8a59",
   "metadata": {},
   "source": [
    "**1.2 Dictionaries**\n",
    "\n",
    "Now let's define a dictionary, which contains key-value pairs that are unordered. This allows you to go and retrieve values using the keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b53a4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Subject metadata\n",
    "subject_data = {\n",
    "    \"ID\": \"S001\",\n",
    "    \"height_cm\": 175,\n",
    "    \"mass_kg\": 72,\n",
    "    \"condition\": \"normal_walking\"\n",
    "}\n",
    "# Let's grab the mass of the subject\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Add our x_positions list to the subject dictionary\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Let's inspect the keys and values in the dictionary\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186b1a73",
   "metadata": {},
   "source": [
    "**1.3 Pandas DataFrames and Series**\n",
    "\n",
    "- The Pandas Series is a 1D *labeled* array (think a single column of data that has a column header tied to it)\n",
    "- The Pandas DataFrame is a 2D table (think of this as an Excel sheet with a tabular, row-and-column format)\n",
    "\n",
    "Pandas has some functions built-in for loading ```csv```, ```txt```, and ```xlsx``` files into a DataFrame for further manipulation. We'll revisit this shortly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7045bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Pandas Series\n",
    "force_z = pd.Series([100, 150, 200, 180], name=\"Fz\")\n",
    "\n",
    "# Check the datatype\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Define a Pandas DataFrame\n",
    "times = [0,0.1,0.2,0.3]\n",
    "forces = [100, 150, 200, 180]\n",
    "data_df = pd.DataFrame({'Time':times, 'Fz':forces})\n",
    "\n",
    "# Pull only the time column using the column header name\n",
    "time_col_header = # YOUR CODE HERE\n",
    "\n",
    "# Pull only the time column using slice indexing\n",
    "time_col_slice = # YOUR CODE HERE\n",
    "\n",
    "# Check datatype(s)\n",
    "print(f\"data type: {type(time_col_header)}\")\n",
    "print(f\"data type: {type(time_col_slice)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15db5c9",
   "metadata": {},
   "source": [
    "# 2. Functions\n",
    "\n",
    "You have already used functions that are built into python  (```type```, ```size```) and a function included in a package you imported (```np.linspace()```). But what about when you need to define your own function? Let's build a simple plotting function using the matplotlib.pyplot package.\n",
    "\n",
    "Key elements of a python function:\n",
    "1. **def keyword** - Informs Python that a function is being defined.\n",
    "2. **Function Name** - A unique identifier used to call the function later in the code. Names must start with a letter or underscore and are case-sensitive.\n",
    "3. **Parentheses ()** - Follow the function name and contain optional parameters.\n",
    "4. **Parameters** - Placeholders for data (arguments) that can be passed into the function when it is called.\n",
    "5. **Colon** : - Marks the end of the function header and signals the start of the function body.\n",
    "6. **Optional -> Return Annotation** - (In modern Python) Can be used to hint the expected return data type, although this is not enforced by Python itself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184555ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# Use our plotting function with our synthetic DataFrame from before\n",
    "plot_data(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cf98f9",
   "metadata": {},
   "source": [
    "# 3. Let's practice with real data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c3639b",
   "metadata": {},
   "source": [
    "**3.1 Define helper functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b06dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a helper function to read in a file from a URL\n",
    "def download_file(url, save_path) -> str:\n",
    "    \"\"\"\n",
    "    Downloads a file from a given URL and saves it to a specified path.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the file to download.\n",
    "        save_path (str): The local path where the file will be saved.\n",
    "\n",
    "    Returns:\n",
    "        save_path (str): The path where the file was saved.\n",
    "\n",
    "    Raises:\n",
    "        requests.exceptions.RequestException: If an error occurs during the download.\n",
    "    \"\"\"\n",
    "    r = requests.get(url, stream=True)\n",
    "    r.raise_for_status()\n",
    "    with open(save_path, 'wb') as f:\n",
    "        for chunk in r.iter_content(chunk_size=8192):\n",
    "            f.write(chunk)\n",
    "    return save_path\n",
    "\n",
    "# Create a helper function to plot multiple timeseries signals from the same dataframe\n",
    "def comparison_plot(df: pd.DataFrame, col_names: list, co_plot: bool = True) -> tuple:\n",
    "    '''\n",
    "    Function that creates an nx1 subplot or co plots n signals, where n is the length of col_names input arg.\n",
    "\n",
    "    Args:\n",
    "    --------\n",
    "        df (DataFrame): DataFrame containing timeseries signals as columns and a column containing a time column\n",
    "        col_names (list): A list of strings that specify which columns of the df to plot\n",
    "        co_plot (bool): An optional flag that switches between co-plotting and creating an nx1 subplot with a shared x-axis\n",
    "\n",
    "    Returns:\n",
    "    ---------\n",
    "        (fig,ax) pair\n",
    "\n",
    "    Raises:\n",
    "    ---------\n",
    "        ValueError: If there is not a column that contains \"time\" (not case sensitive)\n",
    "    '''\n",
    "    \n",
    "    # 1. Validate and Identify the Time Column\n",
    "    # Search for a column name containing \"time\" (case-insensitive)\n",
    "    time_col = next((col for col in df.columns if 'time' in col.lower()), None)\n",
    "    \n",
    "    if time_col is None:\n",
    "        raise ValueError(\"Input DataFrame does not contain a column with 'time' in the name.\")\n",
    "\n",
    "    # 2. Determine Plot Layout\n",
    "    num_vars = len(col_names)\n",
    "    \n",
    "    if co_plot:\n",
    "        # Scenario A: Co-plot (All signals on one axis)\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        \n",
    "        for col in col_names:\n",
    "            ax.plot(df[time_col], df[col], label=col)\n",
    "            \n",
    "        ax.set_xlabel(time_col)\n",
    "        ax.set_ylabel(\"Values\")\n",
    "        ax.set_title(\"Comparison Plot\")\n",
    "        ax.legend(loc='best')\n",
    "        ax.grid(True, linestyle='--', alpha=0.6)\n",
    "        \n",
    "    else:\n",
    "        # Scenario B: Subplots (nx1 grid with shared x-axis)\n",
    "        fig, ax = plt.subplots(num_vars, 1, figsize=(12, 3 * num_vars), sharex=True)\n",
    "        \n",
    "        # If there is only 1 column to plot, ax is not a list. We make it a list for consistency.\n",
    "        if num_vars == 1:\n",
    "            ax = [ax]\n",
    "            \n",
    "        for i, col in enumerate(col_names):\n",
    "            ax[i].plot(df[time_col], df[col], label=col)\n",
    "            ax[i].set_ylabel(col)\n",
    "            ax[i].grid(True, linestyle='--', alpha=0.6)\n",
    "            ax[i].legend(loc='upper right')\n",
    "            \n",
    "        # Set x-label only on the bottom-most plot\n",
    "        ax[-1].set_xlabel(time_col)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94522b57",
   "metadata": {},
   "source": [
    "**3.2 Load and visualize some real force plate data**\n",
    "\n",
    "Let's assume we know that we are given 6 DoF ($F_x, F_y, F_z, M_x, M_y, M_z$) ground reaction force data for someone walking, but we don't know the orientation of the coordinate system. Given the figure below of $F_v$ (superior/inferior), $F_{AP}$ (anterior/posterior), and $F_{ML}$ (medial/lateral) anatomical directions, what is your conclusion? Which cartesian coordinate axis in the data corresponds to which set of anatomical directions?\n",
    "\n",
    "<img src=\"assets/tekscan_locomotion_grf.jpg\" alt=\"Gait GRF Signals\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e4acda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download example force plate data\n",
    "fp_data_filepath = download_file(\"https://uofi.box.com/shared/static/jm3dapmslt2ylbbsi7p0yux3mvpngpib.csv\", \"force_plate_data.csv\")\n",
    "\n",
    "# Read force plate data using built-in pandas csv reader\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Inspect the first few rows of the data using .head() method for pd.DataFrame\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17165fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which columns we wish to plot\n",
    "plot_cols = # YOUR CODE HERE\n",
    "\n",
    "# Use the provided plotting function to visualize the force plate timeseries data\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# If needed, adjust axis limits\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0793e8d",
   "metadata": {},
   "source": [
    "## 4. Debugging\n",
    "\n",
    "\n",
    "For this example, let's say we want to are told the subject's mass for the locomotion force plate data was 75 kg, and we want to find the peak value of the normalized superior/inferior GRF signal. Let's write a function to extract this from our dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1d3a39",
   "metadata": {},
   "source": [
    "**4.1 Define function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3f127e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_normalized_grf(df,subject_mass) -> float:\n",
    "    '''\n",
    "    Extract the peak normalized ground reaction force as a multiple of subject's bodyweight.\n",
    "    \n",
    "    Args:\n",
    "    -------\n",
    "        df (DataFrame) : Dataframe that should contain the superior/inferior GRF signal (in N)\n",
    "        subject_mass (float): The subject's mass (in kg)\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "        peak_norm_grf (float) : The peak normalized GRF value (in N/kg)\n",
    " \n",
    "    '''\n",
    "    mass = 60 # Define the subject mass\n",
    "    Fz = df[:,16] # Extract superior/inferior GRF signal\n",
    "    Fz_max = Fz.max() # Find the maximum value\n",
    "\n",
    "    return Fz_max/subject_mass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ed0cf0",
   "metadata": {},
   "source": [
    "**4.2 Use the function**\n",
    "\n",
    "Attempt to run the cell below. You should observe that the cell does not run, and instead you get what is called a **Traceback**. Let's go over a few basic steps for debugging:\n",
    "1. Read the Traceback bottom to top, examining line numbers (if applicable)\n",
    "2. Use the \"print and inspect\" method to check assumptions (what we think is happening vs. what is really happening)\n",
    "\n",
    "**Note:** Gen AI, when provided file context, can come in very handy here. In some cases, however, it may suggest how to fix the error, but it may create other hidden issues. Understanding what should be happening and how everything works together becomes very important!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cfe3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function we just defined\n",
    "peak_grf = peak_normalized_grf(fp_data,75)\n",
    "\n",
    "# Inspect the value we extracted\n",
    "print(peak_grf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c909d44",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mri_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
